
2. Check the IP addresses of each NIC

Run:

ip addr show   # Linux
ipconfig /all # Windows


Identify which NIC has an IP in the subnet you intend to use for the tunnel.

Avoid using NICs connected to unrelated networks to prevent routing conflicts.

3. Consider routing and gateway

The NIC must have a route to the tunnel endpoint.

For example, if your tunnel endpoint is 203.0.113.10:

ping -I <nic_ip> 203.0.113.10


This tests connectivity via that NIC.

If using Linux, you can specify the outgoing interface when initiating a tunnel:

ip tunnel add tun0 mode gre remote 203.0.113.10 local <NIC_IP> dev <NIC_NAME>
---

Kafka sees this new group.id and creates the group automatically in the __consumer_offsets topic.
ChatGPT said:

Yes ‚Äî exactly. Let me explain precisely how Kafka creates consumer groups automatically and what happens internally in the __consumer_offsets topic.

‚úÖ How Kafka Automatically Creates Consumer Groups

When a consumer application first connects to Kafka with:

group.id=my-group


Kafka does the following automatically, without any command or admin action:

üîπ Step 1 ‚Äî Consumer sends JoinGroup request

The consumer sends a JoinGroup request to the Kafka broker (the Group Coordinator for that group).

Kafka checks:

Does this group.id already exist?

Do I (the broker) have metadata for this group?

If not ‚Üí the group is created in memory.

üîπ Step 2 ‚Äî Kafka creates a new entry in __consumer_offsets

When a consumer sends its first committed offset, Kafka writes a message to:

__consumer_offsets


This is a compact internal topic that stores:

committed offsets

group metadata

generation IDs

leadership info

Kafka writes:

(group.id=my-group, partition=offsets-partition-X) ‚Üí metadata record


This is how the group becomes persistent.

üéØ There is no command like CREATE GROUP.
The act of connecting with a new group.id creates the group.

üîπ Step 3 ‚Äî Broker designated as Group Coordinator

Kafka assigns:

every group to one partition of __consumer_offsets

that partition has a leader broker

that broker becomes the Group Coordinator

Example:

group.id = my-group
‚Üí assigned to __consumer_offsets partition 14
‚Üí broker 2 is leader ‚Üí broker 2 is the coordinator

üîπ Step 4 ‚Äî Group appears in kafka-consumer-groups

Once metadata is written to the offsets topic, running:

kafka-consumer-groups.sh --bootstrap-server ... --list


will show:

my-group


Even if:

the group has no active members

the consumer app is not running now

üß† Why this matters for your issue

Your cluster output showed:

Leader: -1 for __consumer_offsets partition(s)


If the offsets topic partition that stores your group is leaderless, then:

Kafka cannot create the group

Kafka cannot commit offsets

kafka-exporter cannot read lag

kafka-consumer-groups.sh hangs or errors

This is exactly why you see:

exporter timeouts

‚Äúin the middle of a leadership election‚Äù

leader = -1

üîç Want to see which offsets partition your group uses?

Run:

kafka-consumer-groups.sh \
  --bootstrap-server <broker> \
  --describe \
  --group <your-group> \
  --state


It shows:

Coordinator: <broker-id>


Then run:

kafka-topics.sh --describe --topic __consumer_offsets --bootstrap-server <broker>


Look for the partition where <broker-id> is the leader ‚Äî that is the partition holding your group.

If you want, tell me the consumer group name

‚û° I will tell you which offsets partition it uses,
‚û° and why kafka-exporter fails on that exact partition.

---------


Check Kafka server logs for ERROR, WARN, leader change, NetworkProcessor, RequestHandler, DiskError.

Check JMX metrics: request queue sizes, RequestHandlerAvgIdlePercent, replication fetcher times, ISR changes.

Inspect GC logs for pause spikes in same timeframe.

Check disk I/O iostat and iotop to see if storage saturated.

Check network for retransmits and interface errors (/proc/net/snmp, ss -s).


If JVM GC is root cause: consider rolling restart with tuned GC flags; if disk or network is root cause, remediate infra (move partitions, replace disks, fix MTU, NIC drivers).

